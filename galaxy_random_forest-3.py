# -*- coding: utf-8 -*-
"""Galaxy_Random_Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YIk-i0bQ9Xp0OehmP5r2DoW5f10H4N-c
"""

from google.colab import drive
GOOGLE_COLAB= True

path = ""
if GOOGLE_COLAB:
    from google.colab import drive, files
    drive.mount('/content/gdrive/')
    path = "/content/drive/My Drive/Colab Notebooks/"

import pandas as pd
from pandas import Series,DataFrame

# numpy, matplotlib, seaborn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
# %matplotlib inline

# machine learning
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

df = pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/result-14_csv.csv")
print(df.shape)

df.head()

X = df.drop('Class', axis=1)
X = df.drop('name', axis=1)
X = df.drop('type', axis=1)
X = df.drop(['objID','name','ra','dec','run','camcol','rerun','field','type','Class','mjd','specObjID','plate','fiberID'], axis=1)

y = df['Class']

X.head()

from sklearn.model_selection import train_test_split
# implementing train-test-split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)

from sklearn import model_selection
# random forest model creation
rfc = RandomForestClassifier()
rfc.fit(X_train,y_train)
# predictions
rfc_predict = rfc.predict(X_test)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix

rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')

# testing
print("=== Classification Report ===")
print(classification_report(y_test, rfc_predict))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score.mean())

from sklearn.metrics import confusion_matrix
import itertools


mat = confusion_matrix(y_test, rfc_predict)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True)
plt.title('Confusion Matrix (Testing Dataset)')

plt.xlabel('true label')
plt.ylabel('predicted label');

# training
rfc2 = RandomForestClassifier(n_estimators=600, max_depth=300, max_features='sqrt')
rfc2.fit(X_train,y_train)
rfc_predict2 = rfc.predict(X_train)
rfc_cv_score2 = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')
print("=== Confusion Matrix ===")
print(confusion_matrix(y_train, rfc_predict2))
print('\n')
print("=== Classification Report ===")
print(classification_report(y_train, rfc_predict2))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score2)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score2.mean())

from sklearn.metrics import confusion_matrix
import itertools

mat = confusion_matrix(y_train, rfc_predict2)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True)
plt.title('Confusion Matrix (Training Dataset)')

plt.xlabel('true label')
plt.ylabel('predicted label');

# optimization

from sklearn.model_selection import RandomizedSearchCV
# number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# number of features at every split
max_features = ['auto', 'sqrt']

# max depth
max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]
max_depth.append(None)
# create random grid
random_grid = {
 'n_estimators': n_estimators,
 'max_features': max_features,
 'max_depth': max_depth
 }
# Random search of parameters
rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)
# Fit the model
rfc_random.fit(X_train, y_train)
# print results
print(rfc_random.best_params_)

rfc = RandomForestClassifier(n_estimators=600, max_depth=300, max_features='sqrt')
rfc.fit(X_train,y_train)
rfc_predict = rfc.predict(X_test)
rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')
print("=== Confusion Matrix ===")
print(confusion_matrix(y_test, rfc_predict))
print('\n')
print("=== Classification Report ===")
print(classification_report(y_test, rfc_predict))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score.mean())

rfc = RandomForestClassifier(n_estimators=600, max_depth=300, max_features='sqrt')
rfc.fit(X_train,y_train)
rfc_predict = rfc.predict(X_train)
rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')
print("=== Confusion Matrix ===")
print(confusion_matrix(y_train, rfc_predict))
print('\n')
print("=== Classification Report ===")
print(classification_report(y_train, rfc_predict))
print('\n')
print("=== All AUC Scores ===")
print(rfc_cv_score)
print('\n')
print("=== Mean AUC Score ===")
print("Mean AUC Score - Random Forest: ", rfc_cv_score.mean())

#feat_labels = ['z', 'fiberMag_u','modelMag_g','modelMag_r','modelMag_i','modelMag_z','psfMag_u','psfMag_g','psfMag_r','psfMag_i','psfMag_z']
#feat_labels = ['z', 'fiberMag_u','fiberMag_g','fiberMag_r','fiberMag_i','fiberMag_z','U-g','u-r','U-i','U-z','G-r','G-i','G-z','R-i','R-z','I-z','Lick_CN1','Lick_CN2','Lick_Ca4227','Lick_G4300','Lick_Fe4383','Lick_Ca4455',	'Lick_Fe4531','Lick_C4668','Lick_Hb',	'Lick_Fe5015',	'Lick_Mg1',	'Lick_Mg2',	'Lick_Mgb'	,'Lick_Fe5270',	'Lick_Fe5335',	'Lick_Fe5406'	,'Lick_Fe5709',	'Lick_Fe5782'	,'Lick_NaD'	,'Lick_TiO1'	,'Lick_TiO2'	,'B&H_CNB',	'B&H_H+K',	'B&H_CaI'	,'B&H_G'	,'B&H_Hb'	,'B&H_MgG'	,'B&H_MH'	,'B&H_FC',	'B&H_NaD',	'DTT_CaII8498',	'DTT_CaII8542',	'DTT_CaII8662',	'DTT_MgI8807',	'4000Abreak',	'HKratio']
feat_labels = ['z', 'fiberMag_u','fiberMag_g','fiberMag_r','fiberMag_i','fiberMag_z','U-g','u-r','U-i','U-z','G-r','G-i','G-z','R-i','R-z','I-z']

# Create a random forest classifier
clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)

# Train the classifier
clf.fit(X_train, y_train)

# Print the name and gini importance of each feature
for feature in zip(feat_labels, clf.feature_importances_):
    print(feature)

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import accuracy_score
sfm = SelectFromModel(clf, threshold=0.05)

# Train the selector
sfm.fit(X_train, y_train)

for feature_list_index in sfm.get_support(indices=True):
    print(feat_labels[feature_list_index])

features =['U-g','U-z','G-r','G-i','G-z','R-i']
importances = rfc.feature_importances_
indices = np.argsort(importances)

plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()











sns.factorplot('Class','G-i', data=df,size=4,aspect=3)

sns.factorplot('Class','G-z', data=df,size=4,aspect=3)

sns.factorplot('Class','G-r', data=df,size=4,aspect=3)

sns.factorplot('Class','U-g', data=df,size=4,aspect=3)

sns.factorplot('Class','U-z', data=df,size=4,aspect=3)

sns.factorplot('Class','R-i', data=df,size=4,aspect=3)