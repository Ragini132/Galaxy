# -*- coding: utf-8 -*-
"""Galaxy_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jHnxsITrnwJ-0F6KWvEG-WBOKGg8-Cka
"""

from google.colab import drive
GOOGLE_COLAB= True

path = ""
if GOOGLE_COLAB:
    from google.colab import drive, files
    drive.mount('/content/gdrive/')
    path = "/content/drive/My Drive/Colab Notebooks/"

path = "/content/gdrive/My Drive/Colab Notebooks/"
training_data_dir = path + "data/training" # 10 000 * 2
validation_data_dir = path + "data/validation" # 2 500 * 2
test_data_dir = path + "data/testing" # 12 500

import cv2 
import os 
import numpy as np 
from random import shuffle 
from tqdm import tqdm 
from keras.preprocessing.image import ImageDataGenerator

training_data_generator = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True)
validation_data_generator = ImageDataGenerator(rescale=1./255)
test_data_generator = ImageDataGenerator(rescale=1./255)

IMAGE_WIDTH, IMAGE_HEIGHT = 426, 426
BATCH_SIZE = 20


training_generator = training_data_generator.flow_from_directory(
    training_data_dir,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode="binary")
validation_generator = validation_data_generator.flow_from_directory(
    validation_data_dir,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode="binary")
test_generator = test_data_generator.flow_from_directory(
    test_data_dir,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=1,
    class_mode="binary", 
    shuffle=False)

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense

from keras import backend as K

from keras.callbacks import TensorBoard

import matplotlib.pyplot as plt
import math

from keras import optimizers

if K.image_data_format() == 'channels_first':
    input_shape = (3, IMAGE_WIDTH, IMAGE_HEIGHT)
else:
    input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)

model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=input_shape))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(16))
model.add(Activation("relu"))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation("sigmoid"))

model.compile(loss="binary_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

import keras
from keras.callbacks import CSVLogger

TRAINING_LOGS_FILE="/content/gdrive/My Drive/Colab Notebooks/dataa"


class PlotLossesKeras():
    pass

EPOCHS=50
history = model.fit_generator(
    training_generator,
    steps_per_epoch=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=BATCH_SIZE)

'''figure'''
plt.figure(1)

# summarize history for accuracy
#plt.subplot(211)
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')


#plt.subplot(212)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

expected = []
predicted =[]
l=340
i=0
while(i<l):
    if(i<120):
      expected.append(0)
      i=i+1
    else:
      expected.append(1)
      i=i+1
      
print(expected)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.metrics import confusion_matrix


import os
directory = "/content/gdrive/My Drive/Colab Notebooks/data/testing/test"

for filename in os.listdir(directory):
    if filename.endswith(".jpg"):
        print (filename)
        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT)
        open(filename,"w")
        probabilities = model.predict_generator(test_generator, 2)
        for index, probability in enumerate(probabilities):
            image_path = test_data_dir + "/" +test_generator.filenames[index]
            img = mpimg.imread(image_path)
        with open(filename,"a") as fh:
             fh.write(str(probability[0]) + " for: " + image_path + "\n")
             plt.imshow(img)
        if probability > 0.5:
            plt.title("%.2f" % (probability[0]*100) + "% ring")
            predicted.append(1)
        else:
            plt.title("%.2f" % ((1-probability[0])*100) + "% not_ring")
            predicted.append(0)

    plt.show()

import itertools

plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')
plt.colorbar()
plt.title('Confusion Matrix without Normalization')
plt.xlabel('Predicted')
plt.ylabel('Actual')
tick_marks = np.arange(len(set(expected))) # length of classes
class_labels = ['0','1']
tick_marks
plt.xticks(tick_marks,class_labels)
plt.yticks(tick_marks,class_labels)
# plotting text value inside cells
thresh = cf.max() / 2.
for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):
    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')
plt.show();